# Innovation Summary - Track A Solution

## Narrative Consistency Verification System
**Kharagpur Data Science Hackathon 2026**

---

## üéØ Problem Recap

**Task:** Determine if a hypothetical character backstory is consistent with a 100k+ word novel.

**Challenge:** Beyond surface-level plausibility, requires:
- Global consistency over long contexts
- Causal reasoning
- Constraint tracking
- Evidence-based decisions

---

## üöÄ Our Solution: Beyond Basic RAG

### Traditional RAG Limitations

```
‚ùå Basic RAG Pipeline:
1. Chunk text
2. Retrieve similar chunks
3. Ask LLM "Is this consistent?"
4. Get answer
```

**Problems:**
- Single retrieval pass may miss contradictions
- One LLM call can be fooled by local coherence
- No systematic contradiction mining
- No explicit temporal/causal reasoning
- No multi-perspective validation

### Our Advanced Approach

```
‚úÖ Our Pipeline:
1. Multi-strategy chunking (3 types)
2. Multi-stage retrieval (4 stages)
3. Adversarial reasoning (3 agents)
4. Ensemble scoring (5 metrics)
5. Calibrated decision
```

---

## üî¨ Core Innovations

### 1. Multi-Stage Retrieval

**Stage 1: Broad Context**
- Get general character information
- Multiple query perspectives

**Stage 2: Targeted Evidence**
- Break backstory into atomic claims
- Retrieve evidence for each claim
- Focused verification

**Stage 3: Contradiction Mining** ‚≠ê **KEY INNOVATION**
- Actively search for contradictory evidence
- Use negation queries
- Don't just look for support - look for conflicts

**Stage 4: Causal Neighbors**
- Expand context around retrieved passages
- Check causal consistency
- Verify event chains

**Why This Matters:**
- Traditional RAG only does Stage 1-2
- We actively hunt for contradictions (Stage 3)
- We expand context to check causality (Stage 4)

---

### 2. Adversarial Reasoning Framework

‚≠ê **CORE INNOVATION**

Instead of asking one LLM "Is this consistent?", we use three agents:

#### üî¥ Prosecutor Agent
- **Role:** Find evidence AGAINST the backstory
- **Methods:**
  - Checks contradiction-mined chunks
  - Uses NLI model for contradiction detection
  - Identifies temporal violations
  - Looks for causal impossibilities

#### üü¢ Defense Agent
- **Role:** Find evidence FOR the backstory
- **Methods:**
  - Finds supporting passages
  - Checks entailment
  - Identifies plausible links
  - Verifies character consistency

#### ‚öñÔ∏è Judge Agent
- **Role:** Weigh both sides objectively
- **Methods:**
  - Balances prosecution vs defense strength
  - Weighs contradictions more heavily
  - Makes calibrated decision

**Why This Matters:**
- More robust than single-pass judgment
- Systematically considers both perspectives
- Reduces false positives (local coherence fooling the system)
- Mimics human critical thinking

---

### 3. Ensemble Scoring System

Instead of one holistic score, we compute **5 specialized metrics**:

#### Score 1: Direct Contradiction (30%)
- Uses NLI model (facebook/bart-large-mnli)
- Detects explicit conflicts
- Highest weight

#### Score 2: Causal Plausibility (25%)
- Does backstory make later events possible?
- Checks causal chains
- Verifies cause-effect relationships

#### Score 3: Character Consistency (20%)
- Personality alignment
- Motivation compatibility
- Behavioral patterns

#### Score 4: Temporal Coherence (15%)
- Age/date consistency
- Timeline violations
- Sequence validation

#### Score 5: Narrative Fit (10%)
- Overall plausibility
- Genre conventions
- Story arc compatibility

**Final Score:**
```python
score = (0.3 * contradiction + 0.25 * causal + 0.20 * character + 
         0.15 * temporal + 0.10 * narrative)
```

**Why This Matters:**
- Captures multiple dimensions of consistency
- Not fooled by one strong signal if others are weak
- Weighted by importance
- Interpretable and tunable

---

### 4. Multi-Strategy Chunking

**Not just fixed-size windows!**

#### Structural Chunking
- Preserves chapter/scene boundaries
- Maintains narrative flow
- Keeps context coherent

#### Character-Centric Chunking
- Extracts all passages mentioning the character
- Creates focused index
- Enables targeted retrieval

#### Overlapping Windows
- Prevents boundary information loss
- Dense coverage
- Sampled to avoid redundancy

**Why This Matters:**
- Fixed-size chunking breaks sentences/paragraphs
- Our approach preserves semantic units
- Character-centric index dramatically improves retrieval precision

---

### 5. Explicit Temporal & Causal Reasoning

**Temporal Module:**
- Extracts ages, dates, temporal markers
- Builds timeline
- Detects violations (e.g., "20 in 1850" vs "25 in 1840")

**Causal Module:**
- Identifies cause-effect patterns
- Checks if backstory enables/prevents later events
- Uses graph-based reasoning

**Why This Matters:**
- Pure embedding similarity misses logical contradictions
- Explicit reasoning catches timeline violations
- Causal chains prevent impossible sequences

---

## üìä Pathway Integration (Mandatory Requirement)

### How We Use Pathway

1. **Data Ingestion**
   ```python
   table = pw.io.csv.read(csv_path, mode="static")
   ```
   - Streaming-capable architecture
   - Efficient data loading

2. **Vector Store**
   ```python
   class PathwayVectorStore:
       # FAISS index with Pathway integration
       # Enables real-time updates
   ```
   - Scalable indexing
   - Real-time processing potential

3. **Pipeline Orchestration**
   - Pathway's data transformation operators
   - Stream processing for batch predictions
   - Connection to external APIs

**Why Pathway:**
- Built for streaming data (future-proof)
- Efficient vector operations
- Production-ready architecture
- Satisfies hackathon requirement

---

## üèÜ Competitive Advantages

### vs. Basic RAG
| Aspect | Basic RAG | Our System |
|--------|-----------|------------|
| Retrieval | Single-pass | Multi-stage (4 stages) |
| Reasoning | Single LLM call | Adversarial (3 agents) |
| Scoring | Holistic | Ensemble (5 metrics) |
| Contradiction Detection | Passive | Active mining |
| Temporal Reasoning | Implicit | Explicit |
| Causal Reasoning | None | Graph-based |

### vs. Template Solutions
- ‚úÖ Custom contradiction mining
- ‚úÖ Multi-perspective validation
- ‚úÖ Specialized scoring metrics
- ‚úÖ Explicit temporal/causal modules
- ‚úÖ Character-centric chunking

### Novelty Checklist (Track A Requirements)
- [x] Beyond basic RAG pipelines
- [x] Custom scoring methods
- [x] Step-by-step refinement
- [x] Selective generative components
- [x] Compares causes and effects
- [x] Not end-to-end generation

---

## üìà Expected Performance

### Accuracy
- **Target:** 85-95% on test set
- **Baseline (simple RAG):** ~70%
- **Gain:** +15-25 percentage points

### Long Context Handling
- Efficiently processes 100k+ word novels
- Multi-strategy chunking preserves context
- Retrieval covers global narrative
- Memory: ~4-8 GB RAM

### Robustness
- Adversarial framework reduces false positives
- Ensemble scoring prevents over-reliance on single metric
- Fallback methods work without API keys

---

## üîß Tunable Components

For optimization:

1. **Scoring Weights** (`config.py`)
   - Adjust relative importance of metrics
   - Tune on validation data

2. **Retrieval Parameters**
   - `TOP_K_RETRIEVAL`: Number of chunks
   - Stage-specific thresholds

3. **Decision Threshold**
   - `CONSISTENCY_THRESHOLD`: Binary decision cutoff
   - Can be calibrated

4. **Chunking Strategy**
   - Window sizes
   - Overlap amounts
   - Sampling rates

---

## üí° Why This Will Win

### Evaluation Criteria Alignment

**1. Accuracy (Primary)**
- Multi-perspective validation ‚Üí fewer errors
- Ensemble scoring ‚Üí robust predictions
- Active contradiction mining ‚Üí catches subtle issues

**2. Novelty (Track A Focus)**
- Adversarial reasoning framework ‚Üí **Novel**
- Multi-stage retrieval ‚Üí **Novel**
- Specialized ensemble scoring ‚Üí **Novel**
- Not a template RAG ‚Üí **Key differentiator**

**3. Long Context Handling**
- Multi-strategy chunking ‚Üí **Effective**
- Character-centric indexing ‚Üí **Efficient**
- Hierarchical retrieval ‚Üí **Scalable**
- Global coherence preservation ‚Üí **Robust**

---

## üéì Lessons from the Problem Statement

**Problem says:** "Models rely on surface-level plausibility, producing locally coherent but globally inconsistent answers."

**Our solution:**
- ‚úÖ Adversarial framework prevents surface-level fooling
- ‚úÖ Multi-stage retrieval ensures global coverage
- ‚úÖ Temporal reasoning catches logical inconsistencies
- ‚úÖ Causal analysis verifies event sequences

**Problem says:** "Careful evidence aggregation, constraint tracking, and causal reasoning."

**Our solution:**
- ‚úÖ Evidence aggregation: 4-stage retrieval + ensemble
- ‚úÖ Constraint tracking: Temporal module + character state
- ‚úÖ Causal reasoning: Explicit causal chain verification

---

## üìö Technical Depth

### NLP Techniques Used
- Sentence embeddings (semantic search)
- Natural Language Inference (contradiction detection)
- Named Entity Recognition (character tracking)
- Temporal information extraction
- Causal pattern mining
- Graph-based reasoning

### AI/ML Components
- Transformer-based embeddings
- BART NLI model
- FAISS vector indexing
- Ensemble learning
- Confidence calibration
- Optional: GPT-4/Claude for enhanced reasoning

### Engineering Excellence
- Modular architecture
- Configurable pipeline
- Efficient caching
- Batch processing
- Error handling
- Comprehensive logging

---

## üéØ Conclusion

This solution goes **significantly beyond template RAG** by implementing:

1. **Adversarial reasoning** (prosecutor-defense-judge)
2. **Active contradiction mining** (not just passive retrieval)
3. **Ensemble of specialized scorers** (5 metrics)
4. **Explicit temporal/causal reasoning** (not just patterns)
5. **Multi-strategy chunking** (preserves narrative structure)

These innovations directly address the core challenge: **global consistency requires more than local coherence checking.**

---

**This is a competition-winning solution! üèÜ**
