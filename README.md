# Narrative Consistency Verification System

**Kharagpur Data Science Hackathon 2026 - Track A**  
**Problem:** Narrative consistency verification using NLP and Generative AI with Pathway

---

## ğŸ¯ Overview

This system determines whether a hypothetical character backstory is consistent with a long-form narrative (100k+ words novel). It goes **beyond basic RAG** to implement:

- **Multi-perspective adversarial reasoning** (Prosecutor-Defense-Judge framework)
- **Multi-stage retrieval** with active contradiction mining
- **Ensemble scoring** across 5 specialized metrics
- **Temporal and causal reasoning** for global consistency
- **Pathway integration** for data ingestion and vector storage

---

## ğŸ—ï¸ Architecture

```
Novel + Backstory
      â†“
[PATHWAY] Data Ingestion
      â†“
Multi-Strategy Chunking (Semantic + Structural + Character-centric)
      â†“
[PATHWAY] Vector Store + Indexing
      â†“
Multi-Stage Retrieval
  â”œâ”€ Stage 1: Broad Context
  â”œâ”€ Stage 2: Targeted Evidence
  â”œâ”€ Stage 3: Contradiction Mining
  â””â”€ Stage 4: Causal Neighbors
      â†“
Adversarial Reasoning Framework
  â”œâ”€ Prosecutor Agent (finds contradictions)
  â”œâ”€ Defense Agent (finds support)
  â””â”€ Judge Agent (weighs evidence)
      â†“
Ensemble Scoring (5 metrics)
  â”œâ”€ Direct Contradiction (30%)
  â”œâ”€ Causal Plausibility (25%)
  â”œâ”€ Character Consistency (20%)
  â”œâ”€ Temporal Coherence (15%)
  â””â”€ Narrative Fit (10%)
      â†“
Binary Classification (Consistent/Contradict)
```

---

## ğŸš€ Quick Start

### 1. Setup

```bash
# Make setup script executable
chmod +x setup.sh

# Run setup (creates venv, installs dependencies)
./setup.sh
```

### 2. Configure (Optional)

Edit `.env` file to add API keys for better performance:

```bash
OPENAI_API_KEY=your_key_here
ANTHROPIC_API_KEY=your_key_here
```

**Note:** System works without API keys using fallback methods, but performance is enhanced with LLM access.

### 3. Run

```bash
# Activate virtual environment
source venv/bin/activate

# Run the pipeline
python src/run.py
```

Select mode:
- **Mode 1:** Test on training data (with accuracy metrics)
- **Mode 2:** Generate predictions for test data
- **Mode 3:** Both

---

## ğŸ“ Project Structure

```
narrative-consistency/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv              # Training data with labels
â”‚   â”œâ”€â”€ test.csv               # Test data (no labels)
â”‚   â””â”€â”€ books/
â”‚       â”œâ”€â”€ The Count of Monte Cristo.txt
â”‚       â””â”€â”€ In search of the castaways.txt
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingest.py              # Pathway data ingestion
â”‚   â”œâ”€â”€ chunking.py            # Multi-strategy text chunking
â”‚   â”œâ”€â”€ retrieval.py           # Multi-stage retrieval with Pathway
â”‚   â”œâ”€â”€ reasoning.py           # Adversarial reasoning + scoring
â”‚   â”œâ”€â”€ decision.py            # Final classification
â”‚   â””â”€â”€ run.py                 # Main pipeline orchestrator
â”‚
â”œâ”€â”€ config.py                   # Configuration settings
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ setup.sh                    # Automated setup script
â”œâ”€â”€ results.csv                 # Generated predictions (test)
â””â”€â”€ README.md                   # This file
```

---

## ğŸ”¬ Technical Highlights

### 1. **Pathway Integration** âœ… (Mandatory Requirement)

- Used for CSV data ingestion with streaming capabilities
- Vector store integration for efficient retrieval
- Demonstrates real-time processing potential

### 2. **Beyond Basic RAG** ğŸš€

#### Multi-Stage Retrieval
- Not just "retrieve and ask LLM"
- 4 specialized retrieval stages
- Active contradiction mining
- Causal neighbor expansion

#### Adversarial Reasoning
- **Prosecutor Agent:** Actively searches for contradictions
- **Defense Agent:** Finds supporting evidence
- **Judge Agent:** Weighs both perspectives
- More robust than single-pass LLM calls

#### Ensemble Scoring
- 5 specialized metrics with learned weights
- Combines rule-based and neural approaches
- Captures multiple aspects of consistency

### 3. **Long Context Handling** ğŸ“š

#### Smart Chunking
- Structural chunking (preserves chapters/scenes)
- Character-centric chunking (targeted retrieval)
- Overlapping windows (prevents information loss)

#### Memory Mechanisms
- Caches book chunks per character
- Hierarchical retrieval (coarse to fine)
- Efficient FAISS indexing

### 4. **Novel Approaches**

- **Temporal reasoning:** Extracts and validates timelines
- **Causal chain analysis:** Checks if backstory enables later events
- **Claim decomposition:** Verifies atomic facts independently
- **Confidence calibration:** Aligns predicted confidence with accuracy

---

## âš™ï¸ Configuration

Edit `config.py` to customize:

```python
# Models
EMBEDDING_MODEL = "sentence-transformers/all-mpnet-base-v2"
NLI_MODEL = "facebook/bart-large-mnli"
LLM_MODEL = "gpt-4-turbo-preview"

# Chunking
CHUNK_SIZE = 1000
CHUNK_OVERLAP = 200

# Retrieval
TOP_K_RETRIEVAL = 20

# Scoring Weights
WEIGHT_CONTRADICTION = 0.3
WEIGHT_CAUSAL = 0.25
WEIGHT_CHARACTER = 0.2
WEIGHT_TEMPORAL = 0.15
WEIGHT_NARRATIVE = 0.1

# Decision
CONSISTENCY_THRESHOLD = 0.5
```

---

## ğŸ“Š Evaluation Criteria (Track A)

### 1. **Accuracy** âœ…
- Ensemble scoring optimizes for classification accuracy
- Threshold calibration on validation data
- Error analysis and failure mode detection

### 2. **Novelty** âœ…
- Adversarial reasoning framework (not template RAG)
- Multi-stage retrieval with contradiction mining
- Ensemble of specialized scorers
- Temporal and causal reasoning modules

### 3. **Long Context Handling** âœ…
- Multi-strategy chunking preserves narrative structure
- Efficient retrieval covers 100k+ word novels
- Character-centric indexing for targeted search
- Causal neighbor expansion maintains global coherence

---

## ğŸ› ï¸ Dependencies

**Core:**
- `pathway>=0.8.0` - Data streaming and vector store (MANDATORY)
- `sentence-transformers` - Embeddings
- `faiss-cpu` - Fast similarity search
- `transformers` - NLI models

**Optional (for enhanced performance):**
- `openai` - GPT models
- `anthropic` - Claude models

**See `requirements.txt` for complete list**

---

## ğŸ“ˆ Performance Tips

1. **With LLM API:**
   - Add OpenAI or Anthropic API key to `.env`
   - Use GPT-4 for best reasoning quality
   - Expect ~30-60 seconds per example

2. **Without LLM API (fallback mode):**
   - Uses NLI models and rule-based reasoning
   - Faster but slightly lower accuracy
   - Expect ~10-20 seconds per example

3. **Memory:**
   - System caches book chunks per character
   - Needs ~4-8 GB RAM for both novels
   - GPU optional but not required

---

## ğŸ“ Innovation Summary

This solution stands out by:

1. âœ… **Multi-agent adversarial reasoning** instead of single LLM call
2. âœ… **Active contradiction mining** instead of passive retrieval
3. âœ… **Claim-level atomic verification** instead of holistic judgment
4. âœ… **Explicit temporal/causal reasoning** instead of implicit patterns
5. âœ… **Ensemble of specialized scorers** instead of one-size-fits-all
6. âœ… **Pathway integration** for scalable data processing

---

## ğŸ“ Output Format

### Training Mode
```csv
id,book_name,character,prediction,label,confidence,correct,scores,explanation
46,In Search of the Castaways,Thalcave,1,consistent,0.85,True,{...},Backstory is CONSISTENT...
```

### Test Mode (Submission)
```csv
id,label
95,contradict
136,consistent
...
```

---

## ğŸ› Troubleshooting

**Issue:** Import errors  
**Solution:** Run `./setup.sh` to install all dependencies

**Issue:** Out of memory  
**Solution:** Process in smaller batches, reduce `TOP_K_RETRIEVAL`

**Issue:** Slow performance  
**Solution:** Add API key for LLM, or use smaller embedding model

**Issue:** Low accuracy  
**Solution:** Adjust weights in `config.py`, calibrate threshold on training data

---

## ğŸ“œ License

This project is for educational purposes as part of Kharagpur Data Science Hackathon 2026.

---

## ğŸ™ Acknowledgments

- **Pathway** for the streaming data framework
- **Hugging Face** for transformer models
- **OpenAI/Anthropic** for LLM APIs
- **Alexandre Dumas** for "The Count of Monte Cristo"
- **Jules Verne** for "In Search of the Castaways"

---

## ğŸ“§ Contact

For questions or issues, please refer to the hackathon guidelines or contact the organizers.

---

**Good luck! ğŸš€**
